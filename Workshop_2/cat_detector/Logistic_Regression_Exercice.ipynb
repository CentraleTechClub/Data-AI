{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723f5264",
   "metadata": {},
   "source": [
    "# Régression Logistique\n",
    "\n",
    " Vous allez construire un classificateur de régression logistique pour reconnaître les chats. Cet exercice vous guidera étape par étape sur comment faire cela avec un état d'esprit de réseau de neurones, et affûtera également vos intuitions sur l'apprentissage profond.\n",
    "\n",
    "**Instructions :**\n",
    "- N'utilisez pas de boucles (for/while) dans votre code, sauf si les instructions vous le demandent explicitement.\n",
    "- Utilisez `np.dot(X,Y)` pour calculer les produits scalaires.\n",
    "\n",
    "**Vous apprendrez à :**\n",
    "- Construire l'architecture générale d'un algorithme d'apprentissage, incluant :\n",
    "    - Initialiser les paramètres\n",
    "    - Calculer la fonction de coût et son gradient\n",
    "    - Utiliser un algorithme d'optimisation (descente de gradient) \n",
    "- Rassembler les trois fonctions ci-dessus dans une fonction modèle principale, dans le bon ordre.\n",
    "\n",
    "## Note Importante sur la Soumission à l'Auto-Correcteur\n",
    "\n",
    "Avant de soumettre votre exercice à l'auto-correcteur, assurez-vous de ne pas faire ce qui suit :\n",
    "\n",
    "1. Vous n'avez pas ajouté d'instruction `print` supplémentaire dans l'exercice.\n",
    "2. Vous n'avez pas ajouté de cellule de code supplémentaire dans l'exercice.\n",
    "3. Vous n'avez pas modifié les paramètres des fonctions.\n",
    "4. Vous n'utilisez pas de variables globales dans vos exercices notés. Sauf instruction explicite contraire, veuillez vous abstenir et utiliser les variables locales à la place.\n",
    "5. Vous ne modifiez pas le code de l'exercice où ce n'est pas requis, comme créer des variables supplémentaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40f97a",
   "metadata": {},
   "source": [
    "## Table des Matières\n",
    "- [1 - Packages](#1)\n",
    "- [2 - Vue d'ensemble du problème](#2)\n",
    "    - [Exercice 1](#ex-1)\n",
    "    - [Exercice 2](#ex-2)\n",
    "- [3 - Architecture Générale de l'algorithme d'apprentissage](#3)\n",
    "- [4 - Construction des parties de notre algorithme](#4)\n",
    "    - [4.1 - Fonctions d'aide](#4-1)\n",
    "        - [Exercice 3 - sigmoid](#ex-3)\n",
    "    - [4.2 - Initialisation des paramètres](#4-2)\n",
    "        - [Exercice 4 - initialize_with_zeros](#ex-4)\n",
    "    - [4.3 - Propagation avant et arrière](#4-3)\n",
    "        - [Exercice 5 - propagate](#ex-5)\n",
    "    - [4.4 - Optimisation](#4-4)\n",
    "        - [Exercice 6 - optimize](#ex-6)\n",
    "        - [Exercice 7 - predict](#ex-7)\n",
    "- [5 - Fusionner toutes les fonctions dans un modèle](#5)\n",
    "    - [Exercice 8 - model](#ex-8)\n",
    "- [6 - Analyse supplémentaire (exercice facultatif/non noté)](#6)\n",
    "- [7 - Test avec votre propre image (exercice facultatif/non noté)](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807d4a0",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages ##\n",
    "\n",
    "Tout d'abord, exécutons la cellule ci-dessous pour importer tous les packages dont vous aurez besoin pendant cet exercice. \n",
    "- [numpy](https://numpy.org/doc/1.20/) est le package fondamental pour le calcul scientifique avec Python.\n",
    "- [h5py](http://www.h5py.org) est un package courant pour interagir avec un jeu de données stocké dans un fichier H5.\n",
    "- [matplotlib](http://matplotlib.org) est une bibliothèque célèbre pour tracer des graphiques en Python.\n",
    "- [PIL](https://pillow.readthedocs.io/en/stable/) et [scipy](https://www.scipy.org/) sont utilisés ici pour tester votre modèle avec votre propre image à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7a50a",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Vue d'ensemble du Problème ##\n",
    "\n",
    "**Énoncé du problème** : Vous disposez d'un jeu de données (\"data.h5\") contenant :\n",
    "    - un ensemble d'entraînement de m_train images étiquetées comme chat (y=1) ou non-chat (y=0)\n",
    "    - un ensemble de test de m_test images étiquetées comme chat ou non-chat\n",
    "    - chaque image a une forme (num_px, num_px, 3) où 3 correspond aux 3 canaux (RGB). Ainsi, chaque image est carrée (hauteur = num_px) et (largeur = num_px).\n",
    "\n",
    "Vous allez construire un algorithme simple de reconnaissance d'images qui peut correctement classifier les images comme chat ou non-chat.\n",
    "\n",
    "Familiarisons-nous davantage avec le jeu de données. Chargez les données en exécutant le code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données (chat/non-chat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee28833",
   "metadata": {},
   "source": [
    "Nous avons ajouté \"_orig\" à la fin des jeux de données d'images (train et test) car nous allons les prétraiter. Après le prétraitement, nous obtiendrons train_set_x et test_set_x (les étiquettes train_set_y et test_set_y n'ont pas besoin de prétraitement).\n",
    "\n",
    "Chaque ligne de votre train_set_x_orig et test_set_x_orig est un tableau représentant une image. Vous pouvez visualiser un exemple en exécutant le code suivant. N'hésitez pas également à modifier la valeur de `index` et à réexécuter pour voir d'autres images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c318ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'une image\n",
    "index = 12\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "plt.show()\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", c'est une image de '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fbd670",
   "metadata": {},
   "source": [
    "De nombreux bugs logiciels en apprentissage automatique proviennent de dimensions de matrices/vecteurs qui ne correspondent pas. Si vous pouvez garder vos dimensions de matrices/vecteurs cohérentes, vous irez loin dans l'élimination de nombreux bugs. \n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercice 1\n",
    "Trouvez les valeurs pour :<br/>\n",
    "    - m_train (nombre d'exemples d'entraînement)<br/>\n",
    "    - m_test (nombre d'exemples de test)<br/>\n",
    "    - num_px (= hauteur = largeur d'une image d'entraînement)<br/>\n",
    "Pour rappel `train_set_x_orig` est un tableau numpy de forme (m_train, num_px, num_px, 3).<br/> Par exemple, vous pouvez accéder à `m_train` en écrivant `train_set_x_orig.shape[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (≈ 3 lignes de code)\n",
    "# m_train = ...\n",
    "# m_test = ...\n",
    "# num_px = ...\n",
    "# VOTRE CODE COMMENCE ICI\n",
    "\n",
    "\n",
    "# VOTRE CODE SE TERMINE ICI\n",
    "\n",
    "print (\"Nombre d'exemples d'entraînement : m_train = \" + str(m_train))\n",
    "print (\"Nombre d'exemples de test : m_test = \" + str(m_test))\n",
    "print (\"Hauteur/Largeur de chaque image : num_px = \" + str(num_px))\n",
    "print (\"Chaque image est de taille : (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"Forme de train_set_x : \" + str(train_set_x_orig.shape))\n",
    "print (\"Forme de train_set_y : \" + str(train_set_y.shape))\n",
    "print (\"Forme de test_set_x : \" + str(test_set_x_orig.shape))\n",
    "print (\"Forme de test_set_y : \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf445076",
   "metadata": {},
   "source": [
    "**Sortie attendue pour m_train, m_test et num_px** : \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td> m_train </td>\n",
    "    <td> 209 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>m_test</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>num_px</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797692f",
   "metadata": {},
   "source": [
    "Pour plus de commodité, vous devez maintenant redimensionner les images de forme (num_px, num_px, 3) en un tableau numpy de forme (num_px $*$ num_px $*$ 3, 1). Après cela, notre ensemble de données d'entraînement (et de test) est un tableau numpy où chaque colonne représente une image aplatie. Il devrait y avoir m_train (respectivement m_test) colonnes.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercice 2\n",
    "Redimensionnez les ensembles de données d'entraînement et de test de sorte que les images de taille (num_px, num_px, 3) soient aplaties en vecteurs simples de forme (num\\_px $*$ num\\_px $*$ 3, 1).\n",
    "\n",
    "Une astuce lorsque vous voulez aplatir une matrice X de forme (a,b,c,d) en une matrice X_flatten de forme (b$*$c$*$d, a) consiste à utiliser : \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T est la transposée de X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionner les exemples d'entraînement et de test\n",
    "# (≈ 2 lignes de code)\n",
    "# train_set_x_flatten = ...\n",
    "# test_set_x_flatten = ...\n",
    "# VOTRE CODE COMMENCE ICI\n",
    "\n",
    "\n",
    "# VOTRE CODE SE TERMINE ICI\n",
    "\n",
    "# Vérifier que les 10 premiers pixels de la deuxième image sont au bon endroit\n",
    "assert np.all(train_set_x_flatten[0:10, 1] == [196, 192, 190, 193, 186, 182, 188, 179, 174, 213]), \"Mauvaise solution. Utilisez (X.shape[0], -1).T.\"\n",
    "assert np.all(test_set_x_flatten[0:10, 1] == [115, 110, 111, 137, 129, 129, 155, 146, 145, 159]), \"Mauvaise solution. Utilisez (X.shape[0], -1).T.\"\n",
    "\n",
    "print (\"Forme de train_set_x_flatten : \" + str(train_set_x_flatten.shape))\n",
    "print (\"Forme de train_set_y : \" + str(train_set_y.shape))\n",
    "print (\"Forme de test_set_x_flatten : \" + str(test_set_x_flatten.shape))\n",
    "print (\"Forme de test_set_y : \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f0cb9",
   "metadata": {},
   "source": [
    "**Sortie attendue** : \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>Forme de train_set_x_flatten</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Forme de train_set_y</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Forme de test_set_x_flatten</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Forme de test_set_y</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47f5b4",
   "metadata": {},
   "source": [
    "Pour représenter des images en couleur, les canaux rouge, vert et bleu (RGB) doivent être spécifiés pour chaque pixel, donc la valeur du pixel est en fait un vecteur de trois nombres allant de 0 à 255.\n",
    "\n",
    "Une étape de prétraitement courante en apprentissage automatique consiste à centrer et standardiser votre jeu de données, ce qui signifie que vous soustrayez la moyenne de l'ensemble du tableau numpy de chaque exemple, puis divisez chaque exemple par l'écart type de l'ensemble du tableau numpy. Mais pour les jeux de données d'images, il est plus simple et plus pratique et fonctionne presque aussi bien de diviser simplement chaque ligne du jeu de données par 255 (la valeur maximale d'un canal de pixel).\n",
    "\n",
    "Standardisons notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0dc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten / 255.\n",
    "test_set_x = test_set_x_flatten / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc34ba",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "    \n",
    "**Ce qu'il faut retenir :**\n",
    "\n",
    "Étapes courantes pour le prétraitement d'un nouveau jeu de données :\n",
    "- Déterminer les dimensions et formes du problème (m_train, m_test, num_px, ...)\n",
    "- Redimensionner les jeux de données de sorte que chaque exemple soit maintenant un vecteur de taille (num_px \\* num_px \\* 3, 1)\n",
    "- \"Standardiser\" les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b00e5",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Architecture Générale de l'algorithme d'apprentissage ##\n",
    "\n",
    "Il est temps de concevoir un algorithme simple pour distinguer les images de chats des images de non-chats.\n",
    "\n",
    "Vous allez construire une Régression Logistique, en utilisant un état d'esprit de Réseau de Neurones. La figure suivante explique pourquoi **la Régression Logistique est en fait un Réseau de Neurones très simple !**\n",
    "\n",
    "<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Expression mathématique de l'algorithme** :\n",
    "\n",
    "Pour un exemple $x^{(i)}$ :\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "Le coût est ensuite calculé en sommant sur tous les exemples d'entraînement :\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Étapes clés** :\n",
    "Dans cet exercice, vous effectuerez les étapes suivantes : \n",
    "- Initialiser les paramètres du modèle\n",
    "- Apprendre les paramètres du modèle en minimisant le coût  \n",
    "- Utiliser les paramètres appris pour faire des prédictions (sur l'ensemble de test)\n",
    "- Analyser les résultats et conclure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1744f",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Construction des parties de notre algorithme ## \n",
    "\n",
    "Les principales étapes pour construire un Réseau de Neurones sont :\n",
    "1. Définir la structure du modèle (comme le nombre de caractéristiques d'entrée) \n",
    "2. Initialiser les paramètres du modèle\n",
    "3. Boucle :\n",
    "    - Calculer la perte actuelle (propagation avant)\n",
    "    - Calculer le gradient actuel (propagation arrière)\n",
    "    - Mettre à jour les paramètres (descente de gradient)\n",
    "\n",
    "Vous construisez souvent 1-3 séparément puis les intégrez dans une fonction appelée `model()`.\n",
    "\n",
    "<a name='4-1'></a>\n",
    "### 4.1 - Fonctions d'aide\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercice 3 - sigmoid\n",
    "En utilisant votre code de \"Python Basics\", implémentez `sigmoid()`. Comme vous l'avez vu dans la figure ci-dessus, vous devez calculer $sigmoid(z) = \\frac{1}{1 + e^{-z}}$ pour $z = w^T x + b$ afin de faire des prédictions. Utilisez np.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION NOTÉE : sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcule la sigmoïde de z\n",
    "\n",
    "    Arguments:\n",
    "    z -- Un scalaire ou un tableau numpy de n'importe quelle taille.\n",
    "\n",
    "    Retourne:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    \n",
    "    # (≈ 1 ligne de code)\n",
    "    # s = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    \n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b68e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))\n",
    "\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe52f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.5, 0, 2.0])\n",
    "output = sigmoid(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd55547",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "### 4.2 - Initialisation des paramètres\n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Exercice 4 - initialize_with_zeros\n",
    "Implémentez l'initialisation des paramètres dans la cellule ci-dessous. Vous devez initialiser w comme un vecteur de zéros. Si vous ne savez pas quelle fonction numpy utiliser, consultez np.zeros() dans la documentation de la bibliothèque Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f18f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION NOTÉE : initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    Cette fonction crée un vecteur de zéros de forme (dim, 1) pour w et initialise b à 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- taille du vecteur w que nous voulons (ou nombre de paramètres dans ce cas)\n",
    "    \n",
    "    Retourne:\n",
    "    w -- vecteur initialisé de forme (dim, 1)\n",
    "    b -- scalaire initialisé (correspond au biais) de type float\n",
    "    \"\"\"\n",
    "    \n",
    "    # (≈ 2 lignes de code)\n",
    "    # w = ...\n",
    "    # b = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    \n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "\n",
    "assert type(b) == float\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))\n",
    "\n",
    "initialize_with_zeros_test_1(initialize_with_zeros)\n",
    "initialize_with_zeros_test_2(initialize_with_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54754997",
   "metadata": {},
   "source": [
    "<a name='4-3'></a>\n",
    "### 4.3 - Propagation avant et arrière\n",
    "\n",
    "Maintenant que vos paramètres sont initialisés, vous pouvez effectuer les étapes de propagation \"avant\" et \"arrière\" pour apprendre les paramètres.\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Exercice 5 - propagate\n",
    "Implémentez une fonction `propagate()` qui calcule la fonction de coût et son gradient.\n",
    "\n",
    "**Indices** :\n",
    "\n",
    "Propagation avant :\n",
    "- Vous obtenez X\n",
    "- Vous calculez $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- Vous calculez la fonction de coût : $J = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)}))$\n",
    "\n",
    "Voici les deux formules que vous utiliserez : \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63102684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION NOTÉE : propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implémente la fonction de coût et son gradient pour la propagation expliquée ci-dessus\n",
    "\n",
    "    Arguments:\n",
    "    w -- poids, un tableau numpy de taille (num_px * num_px * 3, 1)\n",
    "    b -- biais, un scalaire\n",
    "    X -- données de taille (num_px * num_px * 3, nombre d'exemples)\n",
    "    Y -- vecteur d'étiquettes \"vrai\" (contenant 0 si non-chat, 1 si chat) de taille (1, nombre d'exemples)\n",
    "\n",
    "    Retourne:\n",
    "    grads -- dictionnaire contenant les gradients des poids et du biais\n",
    "            (dw -- gradient de la perte par rapport à w, donc même forme que w)\n",
    "            (db -- gradient de la perte par rapport à b, donc même forme que b)\n",
    "    cost -- coût de log-vraisemblance négative pour la régression logistique\n",
    "    \n",
    "    Conseils:\n",
    "    - Écrivez votre code étape par étape pour la propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # PROPAGATION AVANT (DE X À COST)\n",
    "    # (≈ 2 lignes de code)\n",
    "    # calculer l'activation\n",
    "    # A = ...\n",
    "    # calculer le coût\n",
    "    # cost = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    \n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    # PROPAGATION ARRIÈRE (POUR TROUVER GRAD)\n",
    "    # (≈ 2 lignes de code)\n",
    "    # dw = ...\n",
    "    # db = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    \n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    cost = np.squeeze(np.array(cost))\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae02113",
   "metadata": {},
   "outputs": [],
   "source": [
    "w =  np.array([[1.], [2]])\n",
    "b = 1.5\n",
    "X = np.array([[1., -2., -1.], [3., 0.5, -3.2]])\n",
    "Y = np.array([[1, 1, 0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "\n",
    "assert type(grads[\"dw\"]) == np.ndarray\n",
    "assert grads[\"dw\"].shape == (2, 1)\n",
    "assert type(grads[\"db\"]) == np.float64\n",
    "\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))\n",
    "\n",
    "propagate_test(propagate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e05a6",
   "metadata": {},
   "source": [
    "**Sortie attendue**\n",
    "\n",
    "```\n",
    "dw = [[ 0.25071532]\n",
    " [-0.06604096]]\n",
    "db = -0.1250040450043965\n",
    "cost = 0.15900537707692405\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c985921",
   "metadata": {},
   "source": [
    "<a name='4-4'></a>\n",
    "### 4.4 - Optimisation\n",
    "- Vous avez initialisé vos paramètres.\n",
    "- Vous êtes également capable de calculer une fonction de coût et son gradient.\n",
    "- Maintenant, vous voulez mettre à jour les paramètres en utilisant la descente de gradient.\n",
    "\n",
    "<a name='ex-6'></a>\n",
    "### Exercice 6 - optimize\n",
    "Écrivez la fonction d'optimisation. L'objectif est d'apprendre $w$ et $b$ en minimisant la fonction de coût $J$. Pour un paramètre $\\theta$, la règle de mise à jour est $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, où $\\alpha$ est le taux d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8dc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION NOTÉE : optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):\n",
    "    \"\"\"\n",
    "    Cette fonction optimise w et b en exécutant un algorithme de descente de gradient\n",
    "    \n",
    "    Arguments:\n",
    "    w -- poids, un tableau numpy de taille (num_px * num_px * 3, 1)\n",
    "    b -- biais, un scalaire\n",
    "    X -- données de forme (num_px * num_px * 3, nombre d'exemples)\n",
    "    Y -- vecteur d'étiquettes \"vrai\" (contenant 0 si non-chat, 1 si chat), de forme (1, nombre d'exemples)\n",
    "    num_iterations -- nombre d'itérations de la boucle d'optimisation\n",
    "    learning_rate -- taux d'apprentissage de la règle de mise à jour de la descente de gradient\n",
    "    print_cost -- True pour imprimer la perte toutes les 100 étapes\n",
    "    \n",
    "    Retourne:\n",
    "    params -- dictionnaire contenant les poids w et le biais b\n",
    "    grads -- dictionnaire contenant les gradients des poids et du biais par rapport à la fonction de coût\n",
    "    costs -- liste de tous les coûts calculés pendant l'optimisation, sera utilisée pour tracer la courbe d'apprentissage.\n",
    "    \n",
    "    Conseils:\n",
    "    Vous devez essentiellement écrire deux étapes et itérer à travers elles :\n",
    "        1) Calculer le coût et le gradient pour les paramètres actuels. Utilisez propagate().\n",
    "        2) Mettre à jour les paramètres en utilisant la règle de descente de gradient pour w et b.\n",
    "    \"\"\"\n",
    "    \n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # (≈ 1 ligne de code)\n",
    "        # Calcul du coût et du gradient\n",
    "        # grads, cost = ...\n",
    "        # VOTRE CODE COMMENCE ICI\n",
    "        \n",
    "        \n",
    "        # VOTRE CODE SE TERMINE ICI\n",
    "        \n",
    "        # Récupérer les dérivées de grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # règle de mise à jour (≈ 2 lignes de code)\n",
    "        # w = ...\n",
    "        # b = ...\n",
    "        # VOTRE CODE COMMENCE ICI\n",
    "        \n",
    "        \n",
    "        # VOTRE CODE SE TERMINE ICI\n",
    "        \n",
    "        # Enregistrer les coûts\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "            # Imprimer le coût toutes les 100 itérations d'entraînement\n",
    "            if print_cost:\n",
    "                print (\"Coût après itération %i : %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print(\"Coûts = \" + str(costs))\n",
    "\n",
    "optimize_test(optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ed176",
   "metadata": {},
   "source": [
    "<a name='ex-7'></a>\n",
    "### Exercice 7 - predict\n",
    "La fonction précédente produira les w et b appris. Nous sommes capables d'utiliser w et b pour prédire les étiquettes d'un jeu de données X. Implémentez la fonction `predict()`. Il y a deux étapes pour calculer les prédictions :\n",
    "\n",
    "1. Calculer $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convertir les entrées de a en 0 (si activation <= 0.5) ou 1 (si activation > 0.5), stocker les prédictions dans un vecteur `Y_prediction`. Si vous le souhaitez, vous pouvez utiliser une instruction `if`/`else` dans une boucle `for` (bien qu'il existe également un moyen de vectoriser cela). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION NOTÉE : predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Prédire si l'étiquette est 0 ou 1 en utilisant les paramètres de régression logistique appris (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- poids, un tableau numpy de taille (num_px * num_px * 3, 1)\n",
    "    b -- biais, un scalaire\n",
    "    X -- données de taille (num_px * num_px * 3, nombre d'exemples)\n",
    "    \n",
    "    Retourne:\n",
    "    Y_prediction -- un tableau numpy (vecteur) contenant toutes les prédictions (0/1) pour les exemples dans X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Calculer le vecteur \"A\" prédisant les probabilités qu'un chat soit présent dans l'image\n",
    "    # (≈ 1 ligne de code)\n",
    "    # A = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    \n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        # Convertir les probabilités A[0,i] en prédictions réelles p[0,i]\n",
    "        # (≈ 4 lignes de code)\n",
    "        # if A[0, i] > ... :\n",
    "        #     Y_prediction[0,i] = ...\n",
    "        # else:\n",
    "        #     Y_prediction[0,i] = ...\n",
    "        # VOTRE CODE COMMENCE ICI\n",
    "\n",
    "        \n",
    "        # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[0.1124579], [0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1., -1.1, -3.2],[1.2, 2., 0.1]])\n",
    "print (\"prédictions = \" + str(predict(w, b, X)))\n",
    "\n",
    "predict_test(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e000f",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**Ce qu'il faut retenir :**\n",
    "    \n",
    "Vous avez implémenté plusieurs fonctions qui :\n",
    "- Initialisent (w,b)\n",
    "- Optimisent la perte de manière itérative pour apprendre les paramètres (w,b) :\n",
    "    - Calculer le coût et son gradient \n",
    "    - Mettre à jour les paramètres en utilisant la descente de gradient\n",
    "- Utilisent les (w,b) appris pour prédire les étiquettes d'un ensemble donné d'exemples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa532dd",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Fusionner toutes les fonctions dans un modèle ##\n",
    "\n",
    "Vous allez maintenant voir comment le modèle global est structuré en assemblant tous les blocs de construction (fonctions implémentées dans les parties précédentes) ensemble, dans le bon ordre.\n",
    "\n",
    "<a name='ex-8'></a>\n",
    "### Exercice 8 - model\n",
    "Implémentez la fonction model. Utilisez la notation suivante :\n",
    "    - Y_prediction_test pour vos prédictions sur l'ensemble de test\n",
    "    - Y_prediction_train pour vos prédictions sur l'ensemble d'entraînement\n",
    "    - parameters, grads, costs pour les sorties de optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9448824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION NOTÉE : model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Construit le modèle de régression logistique en appelant la fonction que vous avez implémentée précédemment\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- ensemble d'entraînement représenté par un tableau numpy de forme (num_px * num_px * 3, m_train)\n",
    "    Y_train -- étiquettes d'entraînement représentées par un tableau numpy (vecteur) de forme (1, m_train)\n",
    "    X_test -- ensemble de test représenté par un tableau numpy de forme (num_px * num_px * 3, m_test)\n",
    "    Y_test -- étiquettes de test représentées par un tableau numpy (vecteur) de forme (1, m_test)\n",
    "    num_iterations -- hyperparamètre représentant le nombre d'itérations pour optimiser les paramètres\n",
    "    learning_rate -- hyperparamètre représentant le taux d'apprentissage utilisé dans la règle de mise à jour de optimize()\n",
    "    print_cost -- Défini sur True pour imprimer le coût toutes les 100 itérations\n",
    "    \n",
    "    Retourne:\n",
    "    d -- dictionnaire contenant des informations sur le modèle.\n",
    "    \"\"\"\n",
    "    \n",
    "    # (≈ 1 ligne de code)\n",
    "    # initialiser les paramètres avec des zéros\n",
    "    # w, b = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    \n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    # (≈ 1 ligne de code)\n",
    "    # Descente de gradient\n",
    "    # params, grads, costs = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "    \n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "    \n",
    "    # Récupérer les paramètres w et b du dictionnaire \"params\"\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    \n",
    "    # Prédire les exemples d'ensemble de test/entraînement (≈ 2 lignes de code)\n",
    "    # Y_prediction_test = ...\n",
    "    # Y_prediction_train = ...\n",
    "    # VOTRE CODE COMMENCE ICI\n",
    "\n",
    "    \n",
    "    # VOTRE CODE SE TERMINE ICI\n",
    "\n",
    "    # Imprimer les erreurs d'entraînement/test\n",
    "    if print_cost:\n",
    "        print(\"Précision d'entraînement : {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"Précision de test : {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from public_tests import *\n",
    "\n",
    "model_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f0a62",
   "metadata": {},
   "source": [
    "Si vous passez tous les tests, exécutez la cellule suivante pour entraîner votre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.005, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06188e6e",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle\n",
    "\n",
    "Maintenant que le modèle est entraîné, sauvegardons les poids pour pouvoir les réutiliser plus tard sans avoir à réentraîner le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900df7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Créer le dossier model s'il n'existe pas\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "    print(\"Dossier 'model' créé.\")\n",
    "\n",
    "# Sauvegarder le modèle complet\n",
    "with open('model/logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(logistic_regression_model, f)\n",
    "    \n",
    "print(\"Modèle sauvegardé dans 'model/logistic_regression_model.pkl'\")\n",
    "print(f\"Taille du fichier: {os.path.getsize('model/logistic_regression_model.pkl')} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ff835",
   "metadata": {},
   "source": [
    "### Chargement du modèle sauvegardé\n",
    "\n",
    "Si vous souhaitez charger un modèle précédemment entraîné, exécutez la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8830f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour charger le modèle sauvegardé (décommenter si nécessaire)\n",
    "# with open('model/logistic_regression_model.pkl', 'rb') as f:\n",
    "#     logistic_regression_model = pickle.load(f)\n",
    "# print(\"Modèle chargé depuis 'model/logistic_regression_model.pkl'\")\n",
    "# print(f\"Taux d'apprentissage: {logistic_regression_model['learning_rate']}\")\n",
    "# print(f\"Nombre d'itérations: {logistic_regression_model['num_iterations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142fdf10",
   "metadata": {},
   "source": [
    "**Commentaire** : La précision d'entraînement est proche de 100%. C'est un bon test de santé : votre modèle fonctionne et a une capacité suffisamment élevée pour s'adapter aux données d'entraînement. La précision de test est de 70%. Ce n'est en fait pas mal pour ce modèle simple, compte tenu du petit jeu de données que nous avons utilisé et que la régression logistique est un classificateur linéaire. Mais ne vous inquiétez pas, vous construirez un classificateur encore meilleur la semaine prochaine !\n",
    "\n",
    "De plus, vous voyez que le modèle surajuste clairement les données d'entraînement. Plus tard dans cette spécialisation, vous apprendrez comment réduire le surajustement, par exemple en utilisant la régularisation. En utilisant le code ci-dessous (et en changeant la variable `index`) vous pouvez regarder les prédictions sur les images de l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcec80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'une image qui a été mal classée.\n",
    "index = 9\n",
    "plt.imshow(test_set_x[:, index].reshape((num_px, num_px, 3)))\n",
    "plt.show()\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", vous avez prédit que c'est une image de \\\"\" + classes[int(logistic_regression_model['Y_prediction_test'][0,index])].decode(\"utf-8\") +  \"\\\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f7af8",
   "metadata": {},
   "source": [
    "Traçons également la fonction de coût et les gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer la courbe d'apprentissage (avec les coûts)\n",
    "costs = np.squeeze(logistic_regression_model['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('coût')\n",
    "plt.xlabel('itérations (par centaines)')\n",
    "plt.title(\"Taux d'apprentissage =\" + str(logistic_regression_model[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf42136",
   "metadata": {},
   "source": [
    "**Interprétation** :\n",
    "Vous pouvez voir le coût diminuer. Cela montre que les paramètres sont en cours d'apprentissage. Cependant, vous voyez que vous pourriez entraîner le modèle encore plus sur l'ensemble d'entraînement. Essayez d'augmenter le nombre d'itérations dans la cellule ci-dessus et réexécutez les cellules. Vous pourriez voir que la précision de l'ensemble d'entraînement augmente, mais la précision de l'ensemble de test diminue. C'est ce qu'on appelle le surajustement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10545c8b",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Analyse supplémentaire (exercice facultatif/non noté) ##\n",
    "\n",
    "Félicitations pour avoir construit votre premier modèle de classification d'images. Analysons-le davantage et examinons les choix possibles pour le taux d'apprentissage $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea42ba0",
   "metadata": {},
   "source": [
    "#### Choix du taux d'apprentissage ####\n",
    "\n",
    "**Rappel** :\n",
    "Pour que la Descente de Gradient fonctionne, vous devez choisir le taux d'apprentissage judicieusement. Le taux d'apprentissage $\\alpha$ détermine à quelle vitesse nous mettons à jour les paramètres. Si le taux d'apprentissage est trop grand, nous pouvons \"dépasser\" la valeur optimale. De même, s'il est trop petit, nous aurons besoin de trop d'itérations pour converger vers les meilleures valeurs. C'est pourquoi il est crucial d'utiliser un taux d'apprentissage bien ajusté.\n",
    "\n",
    "Comparons la courbe d'apprentissage de notre modèle avec plusieurs choix de taux d'apprentissage. Exécutez la cellule ci-dessous. Cela devrait prendre environ 1 minute. N'hésitez pas également à essayer différentes valeurs que les trois que nous avons initialisées dans la variable `learning_rates`, et voyez ce qui se passe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print (\"Entraînement d'un modèle avec taux d'apprentissage : \" + str(lr))\n",
    "    models[str(lr)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=1500, learning_rate=lr, print_cost=False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for lr in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(lr)][\"costs\"]), label=str(models[str(lr)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('coût')\n",
    "plt.xlabel('itérations (centaines)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f293a20",
   "metadata": {},
   "source": [
    "**Interprétation** : \n",
    "- Différents taux d'apprentissage donnent des coûts différents et donc des résultats de prédictions différents.\n",
    "- Si le taux d'apprentissage est trop grand (0.01), le coût peut osciller de haut en bas. Il peut même diverger (bien que dans cet exemple, utiliser 0.01 finit par arriver à une bonne valeur pour le coût). \n",
    "- Un coût plus faible ne signifie pas un meilleur modèle. Vous devez vérifier s'il y a éventuellement un surajustement. Cela se produit lorsque la précision d'entraînement est beaucoup plus élevée que la précision de test.\n",
    "- En apprentissage profond, nous recommandons généralement que vous : \n",
    "    - Choisissez le taux d'apprentissage qui minimise mieux la fonction de coût.\n",
    "    - Si votre modèle surajuste, utilisez d'autres techniques pour réduire le surajustement. (Nous en parlerons dans les vidéos ultérieures.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6a37e",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 - Test avec votre propre image (exercice facultatif/non noté) ##\n",
    "\n",
    "Félicitations pour avoir terminé cet exercice. Vous pouvez utiliser votre propre image et voir la sortie de votre modèle. Pour ce faire : <br/><br/>\n",
    "    1. Changez le nom de votre image dans le code suivant en le remplaçant par le lien vers l'image que vous voulez utiliser.<br/>\n",
    "    2. Exécutez le code et vérifiez si l'algorithme est correct (1 = chat, 0 = non-chat) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da999fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changez ceci en le nom de votre fichier image\n",
    "my_image = \"my_image.jpg\"   \n",
    "\n",
    "# Nous prétraitons l'image pour l'adapter à votre algorithme.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(Image.open(fname).resize((num_px, num_px)))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = image / 255.\n",
    "image = image.reshape((1, num_px * num_px * 3)).T\n",
    "my_predicted_image = predict(logistic_regression_model[\"w\"], logistic_regression_model[\"b\"], image)\n",
    "\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", votre algorithme prédit une image de \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3078967",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**Ce qu'il faut retenir de cet exercice :**\n",
    "1. Le prétraitement du jeu de données est important.\n",
    "2. Vous avez implémenté chaque fonction séparément : initialize(), propagate(), optimize(). Ensuite vous avez construit un model().\n",
    "3. L'ajustement du taux d'apprentissage (qui est un exemple d'\"hyperparamètre\") peut faire une grande différence pour l'algorithme. Vous verrez plus d'exemples de cela plus tard dans ce cours !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502defb",
   "metadata": {},
   "source": [
    "Enfin, si vous le souhaitez, nous vous invitons à essayer différentes choses sur ce Notebook. Assurez-vous de soumettre avant d'essayer quoi que ce soit. Une fois que vous avez soumis, les choses que vous pouvez essayer incluent :\n",
    "    - Jouer avec le taux d'apprentissage et le nombre d'itérations\n",
    "    - Essayer différentes méthodes d'initialisation et comparer les résultats\n",
    "    - Tester d'autres prétraitements (centrer les données, ou diviser chaque ligne par son écart type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3178cd1",
   "metadata": {},
   "source": [
    "Bibliographie :\n",
    "- https://www.coursera.org/programs/bachelor-programme-h0abz/learn/neural-networks-deep-learning?source=search\n",
    "\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34496a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
